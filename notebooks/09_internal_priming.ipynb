{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0337c24e-87cf-43a5-9f8b-a058cf78fa4f",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Impact of Internal Priming on IsoQuant\n",
    "\n",
    "We classify the aligned reads as properly primed or not, based on their genomic context and some heuristics. This is accomplished with a command-line tool, `annotate_priming`, which takes a config file that we will create here. It takes a few minutes per BAM file (in parallel) and produces new, annotated BAM files. After running it we count up the reads in the annotated files and produce some plots.\n",
    "\n",
    "We developed the heuristics based on previous tools and literature, as well as inspection of single-cell and bulk data. When inspecting particular cases it is clear that there can be both false positives and false negatives in these calls, but we believe the overall picture of priming is accurate. Developing better datasets and methods for detecting improper priming is an important future direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436157b-0da5-427a-bd7b-2fc48b13c571",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99f12b-4f70-4ef8-aa38-cb7b04f8797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict, Counter\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "import pysam\n",
    "import yaml\n",
    "\n",
    "from mdl.sc_isoform_paper import today\n",
    "from mdl.sc_isoform_paper.constants import MASSEQ_FILENAMES, MASSEQ_KEYS, SAMPLE_COLORS\n",
    "from mdl.sc_isoform_paper.isoquant import IsoQuantClass\n",
    "from mdl.sc_isoform_paper.priming import Priming, count_classes_and_isoquant, tx_count_breakdown\n",
    "from mdl.sc_isoform_paper.plots import plot_isoform_area\n",
    "\n",
    "\n",
    "import pyranges as pr\n",
    "from matplotlib.colors import to_rgb\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from mdl.sc_isoform_paper.deduplicate import deduplicate_bam_exact, deduplicate_bam_with_errors\n",
    "from mdl.sc_isoform_paper.polyAsite_compare import compare_BAM_annot_PAS, plot_stacked_barplot_pas_site_good_matches, plot_stacked_barplot_pas_site_non_good_matches, save_overview_good_vs_non_pdf, save_stacked_bars_per_dataset_pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a6a38-9c45-4647-879f-f9c2c39d5ee5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0cd10c-e632-40a2-8173-e36d1a50565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysam.set_verbosity(0)\n",
    "\n",
    "root_dir = Path.home()\n",
    "sh_dir = root_dir / \"sh_scripts\"\n",
    "reference_path = root_dir / \"reference\"\n",
    "\n",
    "grch38_fasta = reference_path / \"GRCh38\" / \"GRCh38.fasta\"\n",
    "\n",
    "gencode_gtf = reference_path / \"GRCh38.gencode.v39.annotation.basic.gtf\"\n",
    "gencode_polya_gtf = reference_path / \"GRCh38.gencode.v39.polyAs.gtf.gz\"\n",
    "\n",
    "polya_motif_file = reference_path / \"mouse_and_human.polyA_motif.txt\"\n",
    "\n",
    "data_path = root_dir / \"data\" / \"masseq\"\n",
    "minimap_path = data_path / \"20240709_minimap\"\n",
    "isoquant_path = data_path / \"20240722_isoquant\"\n",
    "annotated_path = data_path / \"20250124_annotated\"\n",
    "\n",
    "priming_counts_file = data_path / \"isoquant_priming_counts.pickle\"\n",
    "\n",
    "figure_path = root_dir / \"202501_figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e573a90-fe47-4f4d-95f8-2c1bd43e1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_order = [MASSEQ_KEYS[i] for i in (1, 3, 4)]\n",
    "sample_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3aee62-2a83-4e29-b152-dd6a2b1b9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapped bams\n",
    "mapped_bams = sorted(minimap_path.glob(\"*tagged.mapped.sorted.primary.bam\"))\n",
    "\n",
    "# isoquant prefix for each bam\n",
    "isoquant_paths = [isoquant_path / f\"{MASSEQ_FILENAMES[int(mb.name.split('.')[2])]}\" / \"OUT\" for mb in mapped_bams]\n",
    "\n",
    "len(mapped_bams), len(isoquant_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf087f8b-7765-4b5c-a752-414e01850d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    reference_fasta=str(grch38_fasta),\n",
    "    reference_gtf=str(gencode_gtf),\n",
    "    polya_motif_file=str(polya_motif_file),\n",
    "    polya_annotations=str(gencode_polya_gtf),\n",
    "    priming_parameters=dict(\n",
    "        feature_pre=5,\n",
    "        feature_post=5,\n",
    "        motif_pre=30,\n",
    "        motif_post=20,\n",
    "        pas_pre=5,\n",
    "        pas_post=20,\n",
    "        polya_window=20,\n",
    "        polya_max_len=6,\n",
    "        polya_max_n=12,\n",
    "    ),\n",
    "    output_tag=[\"simple\", \"full\"],\n",
    "    bam_paths=list(map(str, mapped_bams)),\n",
    "    isoquant_paths=list(map(str, isoquant_paths))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f1fdf-5102-43f4-b4c5-6d3ea20e8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path / f\"{today}_priming_config.yaml\", \"w\") as out:\n",
    "    yaml.dump(config, out, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240db925-3e11-4e50-8f79-8b97b8a459d8",
   "metadata": {},
   "source": [
    "### Running the priming classifier\n",
    "\n",
    "Classification is available as a command-line tool in this package, under the name `annotate_priming`:\n",
    "\n",
    "```shell\n",
    "annotate_priming --config-file path/to/priming_config.yaml -p 8 --filter-isoquant-by-bam\n",
    "```\n",
    "\n",
    "This can run in parallel over multiple BAM files at once. Each read will be annotated with a priming class depending on the context of the read alignment.\n",
    "\n",
    "If IsoQuant output paths are provided, the resulting BAM files will have additional information from the read assignment and model construction steps. Note that this option will increase the memory usage of the script as the IsoQuant data must be loaded into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af53ff-3ee4-401e-9c29-a99dd685ed22",
   "metadata": {},
   "source": [
    "### Reading the annotated files\n",
    "\n",
    "Reading through the annotated BAMs only takes a few minutes, but you need those BAMs in the first place. Instead, you can load the pickle of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e2f86-7d25-4195-9024-cee5255ca7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_bams = sorted(annotated_path.glob(\"*annotated.bam\"))\n",
    "len(annotated_bams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5170e-12ad-4e3e-81eb-35da75bff294",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if priming_counts_file.exists():\n",
    "    with priming_counts_file.open(\"rb\") as fh:\n",
    "        tx_priming_counts = pickle.load(fh)\n",
    "else:\n",
    "    tx_priming_counts = defaultdict(Counter)\n",
    "    \n",
    "    with ProcessPoolExecutor(8) as exc:\n",
    "        for k, txc in exc.map(\n",
    "            count_classes_and_isoquant,\n",
    "            (MASSEQ_KEYS[int(fn.name.split(\".\")[2])] for fn in annotated_bams),\n",
    "            annotated_bams\n",
    "        ):\n",
    "            tx_priming_counts[k] += txc\n",
    "\n",
    "if not priming_counts_file.exists():\n",
    "    with priming_counts_file.open(\"wb\") as out:\n",
    "        pickle.dump(tx_priming_counts, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1e5b0-9abc-4f42-901a-2f1ccd868b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplementary table 7\n",
    "def print_priming_calls(tx_priming_counts, include_mito=True):\n",
    "    keys = sorted(tx_priming_counts)\n",
    "\n",
    "    pcc = defaultdict(Counter)\n",
    "    for k in tx_priming_counts:\n",
    "        for (_,_,p), v in tx_priming_counts[k].most_common():\n",
    "            pcc[k][p] += v\n",
    "\n",
    "    if include_mito:\n",
    "        tots = {k: pcc[k].total() for k in keys}\n",
    "    else:\n",
    "        tots = {k: pcc[k].total() - pcc[k][Priming.MITO] for k in keys}\n",
    "\n",
    "    p_set = sorted(Priming, key=lambda p: sum(pcc[k][p] / tots[k] for k in keys), reverse=True)\n",
    "    if not include_mito:\n",
    "        p_set.remove(Priming.MITO)\n",
    "\n",
    "    print(f\"{'':16s}\", *(f\"{' '.join(k):>12}\" for k in keys), sep=\"\\t\")\n",
    "    for p in Priming:\n",
    "        if p is Priming.MITO and not include_mito:\n",
    "            continue\n",
    "        print(f\"{p.name:16s}\", end=\"\\t\")\n",
    "        vs = [pcc[k][p] for k in keys]\n",
    "        print(*(f\"{v / tots[k]:12.2%}\" for k,v in zip(keys, vs)), sep=\"\\t\")\n",
    "\n",
    "    print(f\"\\n{'Total':16s}\", *(f\"{tots[k]:12,}\" for k in keys), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354c14e-9ede-43df-95bc-c147dbabd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_priming_calls(tx_priming_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd8d2e-af3b-4d17-8e42-d24016287c3d",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411a7504-66ec-49c9-bbe1-c4cbdecbf356",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_class, tx_count, tx_ratio = tx_count_breakdown(tx_priming_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9542698-8de1-4227-9df8-c86ab247e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_isoform_area(\n",
    "    sample_order, tx_class, tx_count, tx_ratio,\n",
    "    output_path=figure_path / \"fig2c_priming_area.svg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03273418-2f0f-43f5-821f-4c0a8db1cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in IsoQuantClass:\n",
    "    for k in sample_order:\n",
    "        tx_list = sorted(\n",
    "            (tx for tx in tx_count[k] if tx_count[k][tx] >= 5 and tx_class[k][tx] == txt),\n",
    "            key=tx_ratio[k].get, reverse=True\n",
    "        )\n",
    "        \n",
    "        good_x = np.array([tx_ratio[k][tx] for tx in tx_list])\n",
    "\n",
    "        print(k[0], str(txt), f\"{(good_x == 0).mean():.1%}\", sep=\"\\t\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac37a31-fbb2-4c69-a77b-1f7ed2993d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j, k in enumerate(sample_order):\n",
    "    counts_by_type = defaultdict(list)\n",
    "    for tx in tx_count[k]:\n",
    "        counts_by_type[tx_class[k][tx]].append(tx_count[k][tx])\n",
    "    print(k[0])\n",
    "    for txt in IsoQuantClass:\n",
    "        print(str(txt), *(f\"{v:6,}\" for v in np.percentile(counts_by_type[txt], (5, 20, 50, 80, 95)).astype(int)), sep=\"\\t\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0af0d-3b6c-4777-b482-492fb9003d3f",
   "metadata": {},
   "source": [
    "### Condensed priming plot\n",
    "\n",
    "We created many priming categories based on the different combinations of features that we observed. For figure 2a we condense the results into a few broad categories.\n",
    "\n",
    "The density of the mitochondrial genome made categorization more difficult, as reads were more likely to overlap multiple features in close proximity. We excluded the mitochondrial reads from this analysis by putting them in their own category and not including it in the total count when considering the rate of different priming events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac902c-c2d8-4c19-948f-3c1979d3fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "priming_rates = defaultdict(dict)\n",
    "for s in priming_class_counts:\n",
    "    tot = priming_class_counts[s].total() - priming_class_counts[s][Priming.MITO]\n",
    "    for p in Priming:\n",
    "        priming_rates[s][p] = priming_class_counts[s][p] / tot\n",
    "\n",
    "priming_cats = {\n",
    "    frozenset({Priming.GOOD, Priming.ANNO_GPA, Priming.TX_PAS}): \"Known\\ntranscription sites\",\n",
    "    frozenset({Priming.TX_MOTIF}): \"Unannotated\\ntranscription sites\",\n",
    "    frozenset({Priming.TX_GPA_PAS, Priming.TX_GPA, Priming.TX_GPA_MOTIF, Priming.CDS_GPA, Priming.NC_GPA, Priming.INTERGENIC_GPA, Priming.AS_TX_GPA, Priming.AS_TX_GPA_NC}): \"Suspected\\ninternal priming\",\n",
    "    frozenset({Priming.AS_TX, Priming.AS_TX_NC}): \"Antisense\\nto known transcript\",\n",
    "}\n",
    "priming_cats[frozenset(set(Priming).difference(*priming_cats)) - {Priming.MITO}] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7166f-b871-4186-a732-8217587fb7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6), gridspec_kw={\"hspace\": 0.3})\n",
    "\n",
    "x = np.arange(len(priming_cats))\n",
    "w = 0.3\n",
    "\n",
    "for i, s in enumerate(sample_order):\n",
    "    ax.bar(\n",
    "        x + i * w + 0.05,\n",
    "        [sum(priming_rates[s][p] for p in ps) for ps in priming_cats],\n",
    "        width=w, \n",
    "        color=SAMPLE_COLORS[s[0]], align=\"edge\", label=s[0]\n",
    "    )\n",
    "\n",
    "ax.set_xticks(x + 0.5, priming_cats.values())\n",
    "ax.legend()\n",
    "ax.set_xlim(-0.5, len(priming_cats) + 0.5)\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "\n",
    "plt.savefig(figure_path / \"fig2a_priming_rates.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448cd75-5461-4bbd-8df8-2518d07a6d91",
   "metadata": {},
   "source": [
    "# Merging and deduplicating reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2229966-a6e3-4bf1-a4f6-3454d3ae686a",
   "metadata": {},
   "source": [
    "For this analysis, we are going to deduplicate reads. For that, we will first merge all BAM files from a given library, then deduplicate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0effedda-5694-4ae4-842b-06c240f00a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_annotated_path = annotated_path / \"merged\"\n",
    "\n",
    "merged_annotated_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e4be8-c1d0-469b-8457-84e7ec00906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skera_bams = {\n",
    "    \"10x_3p.primary.annotated.bam\": sorted(annotated_path.glob(\"*.skera.3*annotated.bam\")),\n",
    "    \"10x_5p.primary.annotated.bam\": sorted(annotated_path.glob(\"*.skera.4*annotated.bam\")),\n",
    "    \"PIPseq_8x.primary.annotated.bam\": sorted(annotated_path.glob(\"*.skera.1*annotated.bam\")),\n",
    "    \"PIPseq_6x.primary.annotated.bam\": sorted(annotated_path.glob(\"*.skera.2*annotated.bam\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12616d-2c07-4b9e-b246-b6dface547f7",
   "metadata": {},
   "source": [
    "We will print some samtools commands to run in the terminal along the deduplication steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e3f1b-868d-4704-8e34-6914503ed6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the output in a terminal\n",
    "\n",
    "for k, v in skera_bams.items():\n",
    "    print(\"samtools merge -@ 16 -o \" + (merged_annotated_path / k).as_posix() + \" \\\\\\n    \" + \" \\\\\\n    \".join([f.as_posix() for f in v]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55ff3b-a043-43e3-bf22-f0d1109a4f8a",
   "metadata": {},
   "source": [
    "Here we deduplicate reads with the same cell barcode and UMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb06b2b2-acfb-4510-bd4d-df7f8b6fb698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deduplicate_bam_exact(bam_input=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/10x_3p.primary.annotated.bam\", bam_output=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/10x_3p.primary.annotated.dedup_exact.bam\"))\n",
      "deduplicate_bam_exact(bam_input=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/10x_5p.primary.annotated.bam\", bam_output=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/10x_5p.primary.annotated.dedup_exact.bam\"))\n",
      "deduplicate_bam_exact(bam_input=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/pipseq_8x.primary.annotated.bam\", bam_output=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/pipseq_8x.primary.annotated.dedup_exact.bam\"))\n",
      "deduplicate_bam_exact(bam_input=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/pipseq_6x.primary.annotated.bam\", bam_output=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/pipseq_6x.primary.annotated.dedup_exact.bam\"))\n"
     ]
    }
   ],
   "source": [
    "for k, v in skera_bams.items():\n",
    "    deduplicate_bam_exact(bam_input=(merged_annotated_path / k).as_posix(), bam_output=(merged_annotated_path / k).with_suffix(\".dedup_exact.bam\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fbe009-907e-4166-9bff-918e79c33deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the output in a terminal\n",
    "\n",
    "for k, v in skera_bams.items():\n",
    "    print(f'samtools sort -@ 8 \\\\\\n\\\n",
    "    -o {(merged_annotated_path / k).with_suffix(\".dedup_exact.sorted.bam\").as_posix()} \\\\\\n\\\n",
    "    {(merged_annotated_path / k).with_suffix(\".dedup_exact.bam\").as_posix()}')\n",
    "    print(f'samtools index -@ 8 {(merged_annotated_path / k).with_suffix(\".dedup_exact.bam\").as_posix()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33504322-7c44-4041-b6e8-ff70d14263d4",
   "metadata": {},
   "source": [
    "And now we deduplicate reads with the same cell barcode and UMIs within 1 edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bdceb58a-63fe-427c-849c-a04d66b3e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deduplicate_bam_with_errors(bam_input=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/10x_3p.primary.annotated.dedup_exact.sorted.bam\", bam_output=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/10x_3p.primary.annotated.dedup.bam\"))\n",
      "deduplicate_bam_with_errors(bam_input=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/10x_5p.primary.annotated.dedup_exact.sorted.bam\", bam_output=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/10x_5p.primary.annotated.dedup.bam\"))\n",
      "deduplicate_bam_with_errors(bam_input=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/pipseq_8x.primary.annotated.dedup_exact.sorted.bam\", bam_output=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/pipseq_8x.primary.annotated.dedup.bam\"))\n",
      "deduplicate_bam_with_errors(bam_input=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/pipseq_6x.primary.annotated.dedup_exact.sorted.bam\", bam_output=\"/mnt/data_ont/pip_seq_review/20250124_annotated/merged/pipseq_6x.primary.annotated.dedup.bam\"))\n"
     ]
    }
   ],
   "source": [
    "for k, v in skera_bams.items():\n",
    "    deduplicate_bam_with_errors(bam_input=(merged_annotated_path / k).with_suffix(\".dedup_exact.sorted.bam\").as_posix(), bam_output={(merged_annotated_path / k).with_suffix(\".dedup.bam\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16b2dd-2510-4b2c-a24e-99070a9577d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the output in a terminal\n",
    "\n",
    "for k, v in skera_bams.items():\n",
    "    print(f'samtools sort -@ 8 \\\\\\n\\\n",
    "    -o {(merged_annotated_path / k).with_suffix(\".dedup.sorted.bam\").as_posix()} \\\\\\n\\\n",
    "    {(merged_annotated_path / k).with_suffix(\".dedup.bam\").as_posix()}')\n",
    "    print(f'samtools index -@ 8 {(merged_annotated_path / k).with_suffix(\".dedup.bam\").as_posix()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ec310f-46c7-41ef-a3d7-29de8f55d420",
   "metadata": {},
   "source": [
    "# Performing priming comparison with polyAsite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4997acc7-41db-4b1e-83a8-3042b239773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269c9d79-37b7-4277-89fb-6be3e97c356c",
   "metadata": {},
   "source": [
    "Download the polyASite Atlas BED file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0fb0b-04d7-4b6c-981b-2ab6db6e9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! # wget https://www.polyasite.unibas.ch/download/atlas/3.0/GRCh38.GENCODE_42/atlas.clusters.3.0.GRCh38.GENCODE_42.bed.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbfe3c-bc3e-459b-b84c-d6ab80a317dd",
   "metadata": {},
   "source": [
    "Parse the polyASite BED. (you may need to change the file path depending on where you download the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b91688c-69b6-477a-a542-55ef2d103653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PAS sites into two PyRanges (one per strand)\n",
    "column_names = [\n",
    "    'Chromosome','Start','End','pas_id','expression',\n",
    "    'strand','tissue_support','protocol_count','stringency',\n",
    "    'genomic_class','polyA_signal'\n",
    "]\n",
    "pas_df = pd.read_csv(\"atlas.clusters.3.0.GRCh38.GENCODE_42.bed\", sep=\"\\t\", header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fe2e2-4680-4271-8e1c-92cae75cfa92",
   "metadata": {},
   "source": [
    "Organize the data into ranges per strand for faster comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be788616-f90e-4526-a39b-a9abe1ed8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for PyRanges we need 0-based, half-open intervals:\n",
    "# df['Start'] = df['Start'] - 1  # convert to 0-based\n",
    "    \n",
    "# Split by strand\n",
    "# define 20-unit bins on [0..100]\n",
    "bins       = [0,20,40,60,80,100]\n",
    "bin_labels = pd.IntervalIndex.from_breaks(bins, closed='right')\n",
    "\n",
    "# add a bin column\n",
    "pas_df['bin'] = pd.cut(\n",
    "    pas_df['stringency'],\n",
    "    bins=bins,\n",
    "    labels=bin_labels,\n",
    "    include_lowest=True,\n",
    "    right=True\n",
    ")\n",
    "\n",
    "# split by strand, keep only the columns we need\n",
    "plus_df  = pas_df[pas_df.strand == '+'][[\n",
    "    'Chromosome','Start','End','pas_id','bin','genomic_class'\n",
    "]]\n",
    "minus_df = pas_df[pas_df.strand == '-'][[\n",
    "    'Chromosome','Start','End','pas_id','bin','genomic_class'\n",
    "]]\n",
    "\n",
    "# build C-accelerated interval indexes\n",
    "pas_plus  = pr.PyRanges(plus_df)\n",
    "pas_minus = pr.PyRanges(minus_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86aa3cc-6a83-4db4-ab18-ed4079a3e616",
   "metadata": {},
   "source": [
    "Our polyA classification is stored in the XC tag of reads in each BAM. We are going to parse them to then compare with polyA sites from polyasite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "57b98eb4-468e-434c-883b-6dd0c78a5628",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dedup_bams = {k.split(\".\")[0]: (merged_annotated_path / k).with_suffix(\".dedup.bam\") for k in skera_bams.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "be7dbb27-9c7a-49b4-a861-eadc7575fb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10x_3p': PosixPath('/mnt/data_ont/pip_seq_review/20250124_annotated/merged/10x_3p.primary.annotated.dedup.bam'),\n",
       " '10x_5p': PosixPath('/mnt/data_ont/pip_seq_review/20250124_annotated/merged/10x_5p.primary.annotated.dedup.bam'),\n",
       " 'pipseq_8x': PosixPath('/mnt/data_ont/pip_seq_review/20250124_annotated/merged/pipseq_8x.primary.annotated.dedup.bam'),\n",
       " 'pipseq_6x': PosixPath('/mnt/data_ont/pip_seq_review/20250124_annotated/merged/pipseq_6x.primary.annotated.dedup.bam')}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dedup_bams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d5a6b-ae2d-48a4-91a5-1d4d062e2234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# margin around read end for how far the PAS is allowed to be\n",
    "margin     = 5\n",
    "chunk_size = 200_000\n",
    "\n",
    "# run processing\n",
    "results = {}\n",
    "for label, bam_path in all_dedup_bams.items():\n",
    "    print(f\"\\n>>> Processing {label} ({bam_path})\")\n",
    "    cat_counts, bin_counts, class_counts = compare_BAM_annot_PAS(\n",
    "        bam_path = bam_path,\n",
    "        pas_plus = pas_plus,\n",
    "        pas_minus = pas_minus,\n",
    "        margin = margin,\n",
    "        chunk_size = chunk_size\n",
    "    )\n",
    "    results[label] = {\n",
    "        \"category_counts\": cat_counts,\n",
    "        \"bin_match_counts\": bin_counts,\n",
    "        \"class_bin_counts\": class_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81074ab-2817-42ac-9caf-fc28b7366a1c",
   "metadata": {},
   "source": [
    "Optional overview of counts per category as a check (turn the cell into a \"code\" cell to run)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0998196-b13c-4651-a480-cfd2927571fc",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "cat_counts = results[\"10x_3p\"][\"category_counts\"]\n",
    "bin_counts = results[\"10x_3p\"][\"bin_match_counts\"]\n",
    "class_counts = results[\"10x_3p\"][\"class_bin_counts\"]\n",
    "\n",
    "\n",
    "print(\"== total matches/non‑matches ==\")\n",
    "for tag,c in cat_counts.items():\n",
    "    print(f\"{tag:15}  matched={c['matches']:8,}  non={c['non_matches']:8,}\")\n",
    "\n",
    "print(\"\\n== matches per 20‑unit stringency bin ==\")\n",
    "for (tag,bin_intvl),cnt in bin_counts.items():\n",
    "    print(f\"{tag:15} {str(bin_intvl):9}  {cnt:,}\")\n",
    "\n",
    "print(\"\\n== genomic_class counts per (tag, bin) ==\")\n",
    "for (tag,bin_intvl,gc),cnt in class_counts.items():\n",
    "    print(f\"{tag:15} {str(bin_intvl):9} {gc:5}  {cnt:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a6080-23aa-4246-907b-5d67256495d5",
   "metadata": {},
   "source": [
    "# Stacked Barplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c059c-2b9e-411c-afac-a5b4c0422d98",
   "metadata": {},
   "source": [
    "First, we'll only look at the 10X 3' dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f966b0-5231-4b51-9ec4-c60329a0b512",
   "metadata": {},
   "source": [
    "## Good categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209c40a-6d73-43a3-bbb4-500c935b0651",
   "metadata": {},
   "source": [
    "Our \"good priming\" categories are:  \n",
    "ANNO_GPA  \n",
    "GOOD  \n",
    "TX_PAS  \n",
    "TX_MOTIF  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e42e9a-3f24-472c-9e34-6f31d69c5f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_stacked_barplot_pas_site_good_matches(results, \"10x_3p\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f60ad7c-d3c4-4646-a386-504ea0fd6fe6",
   "metadata": {},
   "source": [
    "## Non-good categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648095a2-43ac-459b-b652-616e52b3c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_stacked_barplot_pas_site_non_good_matches(results, \"10x_3p\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49059d40-c7c6-4d37-8f70-a2c6180d30ec",
   "metadata": {},
   "source": [
    "We will now generate these plots for all datasets at once. We are also making 2 versions for each dataset, one where the y-axis is autoscaled, and one where the y-axis is scaled according to the max across datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3c7fc-99ba-4aa7-bb25-6be965f74a6a",
   "metadata": {},
   "source": [
    "## Overview of good vs non-good proportion per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9519917e-debb-4a30-bcf0-18cdfbf17e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = figure_path / \"stacked_bareplots_good_vs_nongood_overview_by_dataset.pdf\"\n",
    "save_overview_good_vs_non_pdf(results, output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a2e7b-15dc-4004-8188-a626829abd81",
   "metadata": {},
   "source": [
    "## Stacked barplots per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4ea06-151b-4749-b846-2847dc2f6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = figure_path / \"stacked_plotbars_per_dataset.pdf\"\n",
    "save_stacked_bars_per_dataset_pdf(results, output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d854e690-7450-4007-b441-0f00b4a8b743",
   "metadata": {},
   "source": [
    "# Pie charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0178c92-c97a-41db-bbd6-16a4311ee151",
   "metadata": {},
   "source": [
    "## Good and non-good together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e84c42-9e7f-4f05-8f63-f1b894bf770b",
   "metadata": {},
   "source": [
    "First we are making piechars where both good and non-good priming categories are on a single pie chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe1bfa-f18e-4128-bbf5-7b722b3a132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = figure_path / \"piechart_no_binning.pdf\"\n",
    "save_pie_global_nested_pdf(results, output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63eca3-e666-4cef-8df0-c8f4db59f3c8",
   "metadata": {},
   "source": [
    "## Good and non-good on one piechart each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d1d92-7e44-45a0-9fd3-f2eab948eddf",
   "metadata": {},
   "source": [
    "Now we separate good and non-good into one piechart each to better visualize differences in types of matches to polyASite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea8351-8c94-46af-aeb6-e18dfeb880ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = figure_path / \"piechart_good_nongood_nested.pdf\"\n",
    "save_pie_nested_by_class_pdf(results, output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae033b-3428-4e86-b35b-90632534e252",
   "metadata": {},
   "source": [
    "For clarity, this time we are making our inner priming categories be shades of grey to focus the attention on the outer genomic classes' colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6f44a-0f63-4305-adaa-fca08ef387ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = figure_path / \"piechart_good_nongood_grey_inner.pdf\"\n",
    "save_pie_nested_by_class_greyscale_pdf(results, output_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fa",
   "language": "python",
   "name": "fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
