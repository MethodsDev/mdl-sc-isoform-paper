{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5228ac06-69e4-4b77-9348-b1e78f5a1c05",
   "metadata": {},
   "source": [
    "## Monomer processing\n",
    "\n",
    "__Long-read monomer PBMC__ - run on two Sequel IIe flowcells, `m64455e_230922_195123` and `m64455e_230924_064453`\n",
    "   * Raw data: [`gs://mdl-sc-isoform-2025-ms/sequencing_data/pbmc_monomer`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/sequencing_data/pbmc_monomer)\n",
    "   * Contains six samples\n",
    "     1. Fluent 0.8x SPRI\n",
    "     2. Fluent 0.6x SPRI\n",
    "     3. 10x 3' w/ purification\n",
    "     4. 10x 5' w/ purification\n",
    "     5. 10x 3' w/o purification\n",
    "     6. 10x 5' w/o purification\n",
    "\n",
    "### Processing\n",
    "\n",
    "First step is to tag the flowcells with `lima` to identify the samples, using the demux primers found in the `metadata` folder:\n",
    "\n",
    "```bash\n",
    "lima --no-clip m64455e_230922_195123.hifi_reads.bam mas_demux_primers.fasta m64455e_230922_195123.lima.bam\n",
    "lima --no-clip m64455e_230924_064453.hifi_reads.bam mas_demux_primers.fasta m64455e_230924_064453.lima.bam\n",
    "```\n",
    "\n",
    "**Note** `lima` has some funny ideas about file-naming, it might add another `lima` to these so they end with `lima.lima.bam`, check the output folder.\n",
    "\n",
    "Next step is to run `callao` to split the monomers per-index, including artifacts (A-A and Q-Q adapters):\n",
    "\n",
    "```bash\n",
    "callao --include-artifacts --input-bam path/to/m64455e_230922_195123.lima.bam --barcode-fasta mas_demux_primers.fasta --output-stem path/to/m64455e_230922_195123.callao.bam {1..6}\n",
    "callao --include-artifacts --input-bam path/to/m64455e_230924_064453.lima.bam --barcode-fasta mas_demux_primers.fasta --output-stem path/to/m64455e_230924_064453.callao.bam {1..6}\n",
    "```\n",
    "\n",
    "From there, we need to run `marti` on the results. This step requires sample-specific configuration so it's easiest to set up via code.\n",
    "\n",
    "The output from `marti` is available to download at:\n",
    " * [`gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/pbmc_marti_outputs.tgz`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/notebook_checkpoints/pbmc_marti_outputs.tgz)\n",
    " * [`gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/pbmc_marti_unk_outputs.tgz`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/notebook_checkpoints/pbmc_marti_unk_outputs.tgz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392ef02-ce05-4771-9c35-b6ec136c029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import yaml\n",
    "\n",
    "from mdl.sc_isoform_paper import today\n",
    "from mdl.sc_isoform_paper.constants import MONOMER_KEYS\n",
    "from mdl.sc_isoform_paper.marti import CONFIG_DICT, SAMPLE_CONFIG, total_samples\n",
    "from mdl.sc_isoform_paper.plots import plot_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed8626-9797-4aa3-a791-db826ea3b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path.home()\n",
    "sh_dir = root_dir / \"sh_scripts\"\n",
    "\n",
    "data_path = root_dir / \"data\" / \"monomer\"\n",
    "figure_path = root_dir / \"202501_figures\"\n",
    "\n",
    "# path to the marti binary\n",
    "marti_bin = root_dir / \"marti/build/bin/marti\"\n",
    "\n",
    "# path for marti output\n",
    "marti_path = data_path / f\"{today}_marti\"\n",
    "marti_path.mkdir(exist_ok=True)\n",
    "\n",
    "# paths for input files, the output from callao\n",
    "callao_bams = sorted((data_path / \"callao\").glob(\"*bam\"))\n",
    "callao_bams\n",
    "\n",
    "# uncomment to download and extract into the data path\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/pbmc_marti_outputs.tgz - | tar -C {marti_path} -xzv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6033442c-267e-4546-9999-791ab9df6db8",
   "metadata": {},
   "source": [
    "### Marti Configuration\n",
    "\n",
    "We used an error rate of 0.05 and a shorter polyA match, as these settings appeared to yield more reliable results. Because the Fluent PIPseq libraries have a very long barcode we increased the terminal search buffers to 150.\n",
    "\n",
    "Based on the sample number (which maps to a chemistry type) we configure the adapters for the config file:\n",
    "\n",
    "  1. Fluent 0.8x SPRI\n",
    "  2. Fluent 0.6x SPRI\n",
    "  3. 10x 3' w/ purification\n",
    "  4. 10x 5' w/ purification\n",
    "  5. 10x 3' w/o purification\n",
    "  6. 10x 5' w/o purification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58595c-2d97-4ed6-af66-aa6cfb0a460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sh_dir / f\"{today}_monomer_marti.sh\", \"w\") as out:\n",
    "    for cb in callao_bams:\n",
    "        i = int(cb.name.split(\".\")[2])\n",
    "        mp = marti_path / cb.stem\n",
    "    \n",
    "        # make a run directory for each file\n",
    "        mp.mkdir(exist_ok=True, parents=True)\n",
    "        config_file = mp / \"config.yaml\"\n",
    "\n",
    "        # write config file with appropriate parameters\n",
    "        with open(config_file, \"w\") as out2:\n",
    "            print(\n",
    "                yaml.dump(\n",
    "                    {\"input_bam\": str(cb)}\n",
    "                    | SAMPLE_CONFIG[MONOMER_KEYS[i][0]]\n",
    "                    | CONFIG_DICT,\n",
    "                    sort_keys=False\n",
    "                ),\n",
    "                file=out2\n",
    "            )\n",
    "        print(f\"{marti_bin} {config_file}\", file=out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ce9f7-6e3c-4b16-8d9b-402d7ad37af8",
   "metadata": {},
   "source": [
    "### Artifact comparison\n",
    "\n",
    "After we run `marti` we can accumulate the results from the `structure_counts.tsv` files and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bccf99-0bff-4c0f-810a-1bde6204dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ordering of these indices is to group the output nicely\n",
    "full_sample_order = [MONOMER_KEYS[i] for i in [5, 6, 3, 4, 1, 2]]\n",
    "\n",
    "# for brevity, we plot only three samples: unpurified 10x 3' and 5', and the 0.8x SPRI PIPseq\n",
    "sample_order = [MONOMER_KEYS[i] for i in [5, 6, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d950f3a1-e07d-44a0-834b-33adb0a1a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_totals = total_samples(marti_path, MONOMER_KEYS)\n",
    "\n",
    "# artifact types to plot: stuff over 1% in one of the samples\n",
    "overall_total = sum((sample_totals[s] for s in sample_order), start=Counter())\n",
    "key_list = [k for k,_ in overall_total.most_common() if any(sample_totals[s][k] / sample_totals[s].total() > 0.01 for s in sample_order)][1:]\n",
    "\n",
    "plot_artifacts(\n",
    "    sample_order, sample_totals, key_list, title=\"PBMC monomer artifacts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba540c-03bf-47a4-ad48-77b06a0c2971",
   "metadata": {},
   "source": [
    "The plot shows the percentage of various artifacts observed in this dataset (we are not plotting `Proper` reads, which are the majority in all cases). It's clear that 10x 3' has a large proportion of TSO-TSO artifacts, while 10x 5' has a few and also a couple other types. The PIPseq data has a significant number of `OnlyPolyA` reads, which are really due to RNA degradation in the monocyte cells.\n",
    "\n",
    "One thing that's of interest here is the number of Unknown reads. When we inspected the structures responsible for those reads, we saw that they often appear to be TSO-TSO reads that were classified as `Unk` because they have additional `polyA` or `polyT` annotations. This likely due to the short (10bp) threshold we used for the initial classification. So, we did an additional round of `marti` classification on just the Unknown reads, using default settings for the polyA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc74437-2990-4105-aaf1-e2344bc3364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "marti_bams = sorted(marti_path.glob(\"*/*classified.bam\"))\n",
    "marti_path_unk = data_path / f\"{today}_marti_unk\"\n",
    "marti_path_unk.mkdir(exist_ok=True)\n",
    "\n",
    "default_polya_len = { \"min_polyA_match\": 20 }\n",
    "\n",
    "# uncomment to download and extract to marti_path_unk\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/pbmc_marti_unk_outputs.tgz - | tar -C {marti_path_unk} -xzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e926b-0d97-44b5-9ee8-750a7f85fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sh_dir / f\"{today}_monomer_marti_unk.sh\", \"w\") as out:\n",
    "    for mb in marti_bams:\n",
    "        i = int(mb.name.split(\".\")[2])\n",
    "        mp = marti_path_unk / mb.stem\n",
    "        mp.mkdir(exist_ok=True, parents=True)\n",
    "        config_file = mp / \"config.yaml\"\n",
    "\n",
    "        # use samtools to filter out the unknown reads\n",
    "        unk_mb = marti_path_unk / mb.with_suffix(\".unknown.bam\").name\n",
    "        print(f\"samtools view -b -h --tag lb:Unk {mb} > {unk_mb}\", file=out)\n",
    "\n",
    "        # write config file with appropriate parameters\n",
    "        with open(config_file, \"w\") as out2:\n",
    "            print(\n",
    "                yaml.dump(\n",
    "                    {\"input_bam\": str(unk_mb)} \n",
    "                    | SAMPLE_CONFIG[MONOMER_KEYS[i][0]]\n",
    "                    | CONFIG_DICT\n",
    "                    | default_polya_len,\n",
    "                    sort_keys=False\n",
    "                ),\n",
    "                file=out2\n",
    "            )\n",
    "        print(f\"{marti_bin} {config_file}\", file=out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646b74f-877e-4dce-a62b-06cf19d38a7c",
   "metadata": {},
   "source": [
    "After running `marti` again we read in the reclassified results and add them to the previous ones, being careful to remove the `Unk` counts from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93be870-36a1-4d55-b769-81f11e092ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_sample_totals = total_samples(marti_path_unk, MONOMER_KEYS)\n",
    "reclassified_sample_totals = dict()\n",
    "for s in sample_totals:\n",
    "    reclassified_sample_totals[s] = sample_totals[s].copy()\n",
    "    reclassified_sample_totals[s].pop(\"Unk\")\n",
    "    reclassified_sample_totals[s] += unk_sample_totals[s]\n",
    "    assert reclassified_sample_totals[s].total() == sample_totals[s].total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba806edc-1ddc-4daa-bc55-5185b3286518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code prints out the counts for Supplementary Table 2\n",
    "overall_total = sum(reclassified_sample_totals.values(), start=Counter())\n",
    "keys2 = [k for k,_ in overall_total.most_common()]\n",
    "max_len = max(len(k) for k in keys2)\n",
    "\n",
    "print(f\"{'':{max_len}}\", *(f\"{s:>10}\" for s,_ in full_sample_order), sep=\"\\t\")\n",
    "print(f\"{'':{max_len}}\", *(f\"{s:>10}\" for _,s in full_sample_order), sep=\"\\t\")\n",
    "print(f\"{'total':{max_len}}\", *(f\"{reclassified_sample_totals[s].total():10,}\" for s in full_sample_order), sep=\"\\t\")\n",
    "print(f\"{'read classification':{max_len}}\")\n",
    "for k in keys2:\n",
    "    print(f\"{k:{max_len}}\", *(f\"{reclassified_sample_totals[s][k]:10,}\" for s in full_sample_order), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4a968-6583-48f4-9fb8-57cfca9ac8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artifact types to plot: stuff over 1% in one of the samples\n",
    "key_list = [k for k,_ in overall_total.most_common() if any(reclassified_sample_totals[s][k] / reclassified_sample_totals[s].total() > 0.01 for s in sample_order)][1:]\n",
    "\n",
    "plot_artifacts(\n",
    "    sample_order, reclassified_sample_totals, key_list, title=\"PBMC monomer artifacts\",\n",
    "    output_file=figure_path / \"fig1d_artifact_rates.svg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4349f3-035c-4d65-8316-31e70cc819b6",
   "metadata": {},
   "source": [
    "After merging in the reclassification, we see that most of the Unknown reads are now assigned to known structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd61fb43-972a-4e5d-b050-a29d42f1efa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fa",
   "language": "python",
   "name": "fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
