{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459280b7-8596-4dc7-a977-9cabc71dad2b",
   "metadata": {},
   "source": [
    "## MAS-seq processing\n",
    "\n",
    "__MAS-seq PBMC__ - run on eight Revio flowcells\n",
    "   * Raw data: [`gs://mdl-sc-isoform-2025-ms/sequencing_data/pbmc_masseq`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/sequencing_data/pbmc_masseq)\n",
    "   * Contains four samples\n",
    "     * Fluent PIPseq 0.8x SPRI\n",
    "     * Fluent PIPseq 0.6x SPRI\n",
    "     * 10x 3'\n",
    "     * 10x 5'\n",
    "\n",
    "The second set of SMRTcells for the MAS-seq PBMC were run at different concentrations as an optimization experiment, but there was no particular relationship between concentration and output, and the data were incorporated normally.\n",
    "\n",
    "| flowcell | concentration | # reads |\n",
    "|-|-|-|\n",
    "| `m84143_230929_195310_s1` | 350 pM | 3,122,400 |\n",
    "| `m84143_230929_202333_s2` | 400 pM | 4,098,164 |\n",
    "| `m84143_230929_205439_s3` | 450 pM | 3,361,489 |\n",
    "| `m84143_230929_212545_s4` | 500 pM | 3,036,894 |\n",
    "\n",
    "The raw data in the `pbmc_masseq` directory had been needlessly split by PB barcode--at the time of sequencing this was automatically performed by the Revio instrument. The files were re-unified with `lima-undo`.\n",
    "\n",
    "### Processing\n",
    "\n",
    "The zero-th step is to unify the `default` and `unassigned` BAMs with `lima-undo`:\n",
    "\n",
    "```bash\n",
    "mkdir pbmc_masseq/undo\n",
    "lima-undo -j 16 \\\n",
    "    pbmc_masseq/m84063_230829_195231_s1.hifi_reads.default.bam \\\n",
    "    pbmc_masseq/m84063_230829_195231_s1.hifi_reads.unassigned.bam \\\n",
    "    pbmc_masseq/undo/m84063_230829_195231_s1.undo.bam\n",
    "...\n",
    "```\n",
    "\n",
    "The First step is to tag the flowcells with `lima` to identify the samples, using the demux primers found in the `resources` folder:\n",
    "\n",
    "```bash\n",
    "mkdir pbmc_masseq/lima\n",
    "lima -j 16 --no-clip \\\n",
    "    pbmc_masseq/undo/m84063_230829_195231_s1.undo.bam \\\n",
    "    metadata/mas_demux_primers.fasta \\\n",
    "    pbmc_masseq/lima/m84063_230829_195231_s1.lima.bam\n",
    "...\n",
    "```\n",
    "\n",
    "**Note** `lima` has some quirks with file-naming, it might add another `lima` to these so they end with `lima.lima.bam`, check the output folder.\n",
    "\n",
    "Next step is to run `callao` to split the samples per-index, including artifacts (A-A and Q-Q adapters):\n",
    "\n",
    "```bash\n",
    "mkdir pbmc_masseq/callao\n",
    "callao --include-artifacts \\\n",
    "    --barcode-fasta metadata/mas_demux_primers.fasta \\\n",
    "    --input-bam pbmc_masseq/lima/m84063_230829_195231_s1.lima.bam \\\n",
    "    --output-stem pbmc_masseq/callao/m84063_230829_195231_s1.callao.bam \\\n",
    "    {1..4}\n",
    "...\n",
    "```\n",
    "\n",
    "Next, we run `skera` on each of the samples. This requires an index-specific adapter file, as the `A` and `Q` adapters are different based on the index we used. The necessary files are in the `metadata.tgz` file. We will create a bash script for running `skera` in this notebook.\n",
    "\n",
    "From there, we need to run `marti` on the results. This step requires sample-specific configuration so it's easiest to set up via code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436157b-0da5-427a-bd7b-2fc48b13c571",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b347f-aa3c-4748-ba09-1af4ccdaa64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import yaml\n",
    "\n",
    "from mdl.sc_isoform_paper import today\n",
    "from mdl.sc_isoform_paper.constants import MASSEQ_KEYS\n",
    "from mdl.sc_isoform_paper.marti import CONFIG_DICT, SAMPLE_CONFIG\n",
    "from mdl.sc_isoform_paper.skera import read_length_csv, read_ligation_csv\n",
    "from mdl.sc_isoform_paper.plots import plot_concat_and_ligations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5656bc-7f69-46c6-ae92-4fdcb82f0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path.home()\n",
    "sh_dir = root_dir / \"sh_scripts\"\n",
    "\n",
    "data_path = root_dir / \"data\" / \"masseq\"\n",
    "figure_path = root_dir / \"202501_figures\"\n",
    "\n",
    "# path for output of skera\n",
    "skera_path = data_path / f\"{today}_skera\"\n",
    "skera_path.mkdir(exist_ok=True)\n",
    "\n",
    "# path to the marti binary\n",
    "marti_bin = root_dir / \"marti/build/bin/marti\"\n",
    "\n",
    "# path for marti output\n",
    "marti_path = data_path / f\"{today}_marti\"\n",
    "marti_path.mkdir(exist_ok=True)\n",
    "\n",
    "# paths for input files, the output from callao\n",
    "callao_bams = sorted((data_path / \"callao\").glob(\"*bam\"))\n",
    "callao_bams\n",
    "\n",
    "# uncomment to download and extract into the data path\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/3dg_marti_outputs.tgz - | tar -C {marti_path} -xzv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83afa38-ece6-48c0-ad28-c88d139df7c2",
   "metadata": {},
   "source": [
    "### deconcat the multimer libraries and run marti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae16dbb-25d5-42e6-a507-41f77375d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sh_dir / f\"{today}_skera.sh\", \"w\") as out:\n",
    "    for mcb in callao_bams:\n",
    "        base = mcb.name.split(\".\")[0]\n",
    "        ix = mcb.name.rsplit(\".\", 2)[1]\n",
    "\n",
    "        # echo the command so we see progress\n",
    "        print(\n",
    "            f\"echo skera split -j 16 {mcb}\",\n",
    "            f\"metadata/mas16_primers_{ix}.fasta\",\n",
    "            skera_path / f\"{base}.skera.{ix}.bam\",\n",
    "            file=out\n",
    "        )\n",
    "        print(\n",
    "            f\"skera split -j 16 {mcb}\",\n",
    "            f\"metadata/mas16_primers_{ix}.fasta\",\n",
    "            skera_path / f\"{base}.skera.{ix}.bam\",\n",
    "            file=out\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb7bae-0575-45f8-aa2d-42d520ceafd7",
   "metadata": {},
   "source": [
    "## MAS-seq QC\n",
    "\n",
    "After running `skera` we make some basic QC plots based on the output. To re-generate the figures without processing these files at all, download and load `pbmc_skera_stats.pickle` file from `gs://mdl-sc-isoform-2025-ms/notebook_checkpoints`, and skip to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789293d-b255-4519-9b05-cde18ec24c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = [MASSEQ_KEYS[i] for i in (1, 2, 3, 4)]\n",
    "\n",
    "skera_stats_file = data_path / \"pbmc_skera_stats.pickle\"\n",
    "\n",
    "# defining bins for the length histograms\n",
    "bins = np.linspace(0, 2500, 126)\n",
    "\n",
    "# uncomment to download\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/pbmc_skera_stats.pickle.tgz {data_path}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02f022-c3a2-43b5-bcab-70875e28c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "if skera_stats_file.exists():\n",
    "    with open(skera_stats_file, \"rb\") as fh:\n",
    "        counts, sread_hists, sread_percentiles, read_lengths = pickle.load(fh)\n",
    "else:\n",
    "    skera_ligations = sorted(skera_path.glob(\"*ligations.csv\"))\n",
    "    skera_read_len = sorted(skera_path.glob(\"*read_lengths.csv\"))\n",
    "\n",
    "    counts = dict()\n",
    "    sread_hists = dict()\n",
    "    sread_percentiles = dict()\n",
    "\n",
    "    read_lengths = defaultdict(list) \n",
    "    sread_lengths = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01869ee-370e-4afe-8ab6-f39fbb4ebb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(counts) == 0:\n",
    "    for i in MASSEQ_KEYS:\n",
    "        counts[MASSEQ_KEYS[i]] = np.dstack(\n",
    "            [read_ligation_csv(skl, 16) for skl in skera_ligations\n",
    "             if int(skl.name.split(\".\")[2]) == i]\n",
    "        ).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74384e-09aa-488f-9dd7-d4b6fb1acccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(read_lengths) == 0:\n",
    "    read_lengths = defaultdict(list)\n",
    "    sread_lengths = defaultdict(list)\n",
    "    for srl in skera_read_len:\n",
    "        i = int(srl.name.split(\".\")[2])\n",
    "        read_lens, sread_lens = read_length_csv(srl)\n",
    "        read_lengths[MASSEQ_KEYS[i]].extend(read_lens)\n",
    "        sread_lengths[MASSEQ_KEYS[i]].extend(sread_lens)\n",
    "\n",
    "    read_lengths = {k: np.array(read_lengths[k]) for k in sample_names}\n",
    "    sread_lengths = {k: np.array(sread_lengths[k]) for k in sample_names}\n",
    "\n",
    "    for k in sample_names:\n",
    "        sread_percentiles[k] = np.percentile(sread_lengths[k][:, 0], (5, 50, 95))\n",
    "        sread_hists[k] = np.histogram(sread_lengths[k][:, 0], bins=bins)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bcce3-a771-44b1-832b-7a131a57b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the stats file\n",
    "if not skera_stats_file.exists():\n",
    "    with open(skera_stats_file, \"wb\") as out:\n",
    "        pickle.dump(\n",
    "            (counts, sread_hists, sread_percentiles, read_lengths), out\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca3f74f-c16e-4458-99f2-7de765c0e603",
   "metadata": {},
   "source": [
    "### Looking at read length and s-read length distributions\n",
    "\n",
    "We'll print out some statistics on the array deconcatenation. Always worth checking that the arrays were constructed properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab9f02-aca1-4207-816f-db51541a0834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and 90% interval for length of arrays\n",
    "for k in sample_names:\n",
    "    print(\n",
    "        f\"{' '.join(k):12s}\",\n",
    "        f\"{np.percentile(read_lengths[k][:, 0], (5, 90, 95))}\",\n",
    "        sep=\"\\t\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55cc0fc-1737-4f85-83ec-8e22f81b4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of arrays that are 16-mer\n",
    "for k in sample_names:\n",
    "    print(\n",
    "        f\"{' '.join(k):12s}\",\n",
    "        f\"{len(read_lengths[k]):,d}\", \n",
    "        f\"{(read_lengths[k][:, 1] == 16).sum() / len(read_lengths[k]):.2%}\",\n",
    "        sep=\"\\t\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac924d2-1c6b-4b45-8844-b1d781cd5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median and 90% interval for s-read length\n",
    "for k in sample_names:\n",
    "    print(\n",
    "        f\"{' '.join(k):12s}\",\n",
    "        f\"{sread_percentiles[k]}\",\n",
    "        sep=\"\\t\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af3167-6fe8-4d95-bd7a-db91fe331e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(18, 5))\n",
    "\n",
    "ax.hist(\n",
    "    [bins[:-1] for _ in sample_names],\n",
    "    weights=[sread_hists[k] for k in sample_names],\n",
    "    label=[\" \".join(k) for k in sample_names],\n",
    "    histtype=\"step\", alpha=0.5, bins=bins, density=True, linewidth=2\n",
    ")\n",
    "\n",
    "ax.legend()\n",
    "plt.title(\"Read length distribution for MASseq data\")\n",
    "plt.savefig(figure_path / \"supp_fig4_read_len_distribution.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648560c2-d718-4192-814d-62ebddcb14dc",
   "metadata": {},
   "source": [
    "Here we look at the overall read length distribution for s-reads from these experiments. The mRNA degradation in the PIPseq data is clearly visible as a large density of shorter reads.\n",
    "\n",
    "It's difficult to see much more detail in terms of the different technologies--they all have a similar distribution for the longer reads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77256fa9-11d8-4470-acec-4692678086ba",
   "metadata": {},
   "source": [
    "### Ligation histograms and heatmaps\n",
    "\n",
    "Here we make the standard QC plots for MAS-seq: the distribution of array length (separated by array size) and the ligation heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c98f48-5264-428f-95d7-a43219f929e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sample_names:\n",
    "    plot_concat_and_ligations(read_lengths[k], counts[k], True)\n",
    "    plt.suptitle(\" \".join(k))\n",
    "    plt.savefig(figure_path / f\"supplementary_fig5_{'-'.join(k)}.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564290e1-97e0-4ff1-adf7-d90e69c9e1aa",
   "metadata": {},
   "source": [
    "These plots are the standard QC plots for MAS-seq experiments, showing that all four of these runs are primarily 16-mer arrays and there are essentially no arrays with incorrectly-paired adapters.\n",
    "\n",
    "There are slightly more short arrays in the PIPseq data than in the 10x samples. This is likely due to the fact that no artifact purification was done on the PIPseq libraries--the artifact rate for PIPseq is low enough that purification is not necessary, but the array-disrupting artifacts are not entirely absent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f9c6a-14a5-47d6-9500-8c117a265906",
   "metadata": {},
   "source": [
    "# Annotating reads with marti\n",
    "\n",
    "After running `skera`, we need to run `marti`, similar to how we processed the monomer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb88175-972b-4ecb-b9b1-e26dcfafbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "skera_bams = list(skera_path.glob(\"*skera.bam\"))\n",
    "skera_bams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab1e56-2b95-4096-92c5-e12b29deed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sh_dir / f\"{today}_marti.sh\", \"w\") as out:\n",
    "    for sb in skera_bams:\n",
    "        i = int(sb.name.rsplit(\".\", 2)[1])\n",
    "        mp = marti_path / sb.stem\n",
    "\n",
    "        # make a run directory for each file\n",
    "        mp.mkdir(exist_ok=True)\n",
    "        config_file = mp / \"config.yaml\"\n",
    "\n",
    "        # write config file with appropriate parameters\n",
    "        with open(config_file, \"w\") as out2:\n",
    "            print(\n",
    "                 yaml.dump(\n",
    "                    {\"input_bam\": str(sb)}\n",
    "                    | SAMPLE_CONFIG[MASSEQ_KEYS[i][0]]\n",
    "                    | CONFIG_DICT,\n",
    "                    sort_keys=False\n",
    "                ),\n",
    "                file=out2\n",
    "            )\n",
    "\n",
    "        print(f\"{marti_bin} {config_file}\", file=out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c75483-b0ca-492d-b08c-8cfb3dd5c9bc",
   "metadata": {},
   "source": [
    "After `marti` has completed we can move on to barcode matching/tagging and mapping with `minimap2`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fa",
   "language": "python",
   "name": "fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
