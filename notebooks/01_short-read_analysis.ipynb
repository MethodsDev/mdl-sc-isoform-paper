{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed673fbb-fcc0-48f4-8b2f-198033614585",
   "metadata": {},
   "source": [
    "## Short-read Analysis\n",
    "\n",
    "This notebooks produces basic statistics and figures for the short-read data for single-cell PBMCs: number of cells, nUMIs/cell, nGenes/cell, etc. Next, we subsample to a roughly equal number of reads per cell, recompute our statistics, and cluster the three datasets.\n",
    "\n",
    "The subsampling portion of the notebook relies on [`bugzapper`](https://github.com/MethodsDev/bugzapper.git), a small Rust+Python library for parsing BAM files and counting up the barcode and UMIs. To reproduce the subsampling one will need to install this package and download the aligned BAM files. The package can installed with `pip install git+ssh://git@github.com/MethodsDev/bugzapper.git`.\n",
    "\n",
    "Data is from the `230924_SL-EXC_0072_A2275VKLT3` flowcell and contains four samples:\n",
    "\n",
    "  * 10x 3' PBMC\n",
    "  * 10x 5' PBMC\n",
    "  * Fluent PBMC (0.8x SPRI)\n",
    "  * Fluent Barnyard (K562 + 3T3)\n",
    "\n",
    "The data files for this notebook (the output from CellRanger and PIPseeker) are in a tarball: [`gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_matrices.tgz`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_matrices.tgz). Download is 2.1GB.\n",
    "\n",
    "The pickle files (checkpoints to avoid computing anything) are in separate files:\n",
    "  * [`gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_full_stats.pickle`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_full_stats.pickle)\n",
    "  * [`gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_clustering_100k.pickle`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_clustering_100k.pickle)\n",
    "  * [`gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_graphs_100k.pickle`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_graphs_100k.pickle)\n",
    "  * [`gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_stats_100k.pickle`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_stats_100k.pickle)\n",
    "  * [`gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/subsample_stats.pickle`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/notebook_checkpoints/subsample_stats.pickle)\n",
    "\n",
    "These take up about 150M in total.\n",
    "\n",
    "Output from CellRanger and PIPseeker:\n",
    "  * [`gs://mdl-sc-isoform-2025-ms/pbmc_pipseq`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/pbmc_pipseq)\n",
    "  * [`gs://mdl-sc-isoform-2025-ms/pbmc_10x_3p`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/pbmc_10x_3p)\n",
    "  * [`gs://mdl-sc-isoform-2025-ms/pbmc_10x_5p`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/pbmc_10x_5p)\n",
    "  * [`gs://mdl-sc-isoform-2025-ms/barnyard_pipseq`](https://console.cloud.google.com/storage/browser/mdl-sc-isoform-2025-ms/barnyard_pipseq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7d2f2-98f1-4841-8111-07b17c21dc78",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007043c3-6136-4d10-9abe-cc1775e15984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import bugzapper\n",
    "\n",
    "# a bunch of functions for single-cell analysis\n",
    "# installed from www.github.com/methodsdev/isoscelles\n",
    "import mdl.isoscelles.neighbors as nbrs\n",
    "from mdl.isoscelles.gene_selection import fit_poisson\n",
    "from mdl.isoscelles.io import read_mtx\n",
    "from mdl.isoscelles.leiden import recursive_cluster, cluster_leaf_nodes, cluster_labels\n",
    "\n",
    "# code from this paper repository\n",
    "from mdl.sc_isoform_paper.constants import SHORTREAD_KEYS, SHORTREAD_NAMES, SAMPLE_COLORS\n",
    "from mdl.sc_isoform_paper.graph_layout import layout_graph\n",
    "from mdl.sc_isoform_paper.plots import plot_dists, plot_marker_dotplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca31b24-b2e3-4ad4-8968-d5c887d21df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant for formatting legend \n",
    "line_kwargs = dict(\n",
    "    xdata=[0], ydata=[0], marker=\"o\", linewidth=0, markeredgewidth=0, markersize=10\n",
    ")\n",
    "\n",
    "# use a seed to generate a consistent subsample\n",
    "rng = np.random.default_rng(seed=sum(map(ord, \"MDL\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c4c6dc-8978-4f1c-b61f-0e38b0a4d04e",
   "metadata": {},
   "source": [
    "#### File I/O and preprocessing\n",
    "\n",
    "The raw files are quite slow to process, and bulky to keep in RAM. It's convenient to convert them to sparse arrays and save as `.npz` files. With enough RAM it'd be okay to just store them in memory instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87ff24-0cb2-47b0-a42f-3d9090dd1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the short-read data (output from cellranger + pipseeker)\n",
    "root_dir = Path.home()\n",
    "data_path = root_dir / \"data\"\n",
    "figure_path = root_dir / \"202501_figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf36bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download to local disk\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/shortread_matrices.tgz - | tar -C {data_path} -xzv\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/\"shortread*.pickle\" {data_path}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c007a-41e9-4233-a5ba-5f4533059132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 10x mtx files\n",
    "for fp in data_path.glob(\"10x*/outs/raw_feature_bc_matrix/matrix.mtx.gz\"):\n",
    "    out_fp = fp.parent.parent / f\"{fp.parent.parent.parent.name}.npz\"\n",
    "    print(fp, out_fp)\n",
    "    if out_fp.exists():\n",
    "        print(\"File already exists\")\n",
    "        continue\n",
    "\n",
    "    matrix = read_mtx(fp)\n",
    "    sparse.save_npz(out_fp, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6706b-803f-4e1f-a540-871d14fb1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the PIPseq mtx files. We'll convert the barnyard data while we're here\n",
    "for fp in data_path.glob(\"pipseq_*/raw_matrix/matrix.mtx.gz\"):\n",
    "    out_fp = fp.parent / f\"{fp.parent.parent.name}.npz\"\n",
    "    print(fp, out_fp)\n",
    "    if out_fp.exists():\n",
    "        print(\"File already exists\")\n",
    "        continue\n",
    "\n",
    "    matrix = read_mtx(fp)\n",
    "    sparse.save_npz(out_fp, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04a256",
   "metadata": {},
   "source": [
    "### Loading feature and barcode lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ddfaea-0fc3-4e78-8765-a48e01692f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_dict = dict()\n",
    "feature_dict = dict()\n",
    "gene_dict_i = dict()\n",
    "\n",
    "for fp in data_path.glob(\"10x*/outs/raw_feature_bc_matrix/\"):\n",
    "    k = fp.parent.parent.name\n",
    "    print(fp)\n",
    "    with gzip.open(fp / \"barcodes.tsv.gz\", \"rt\") as fh:\n",
    "        bc_dict[k] = [line.strip() for line in fh]\n",
    "\n",
    "    with gzip.open(fp / \"features.tsv.gz\", \"rt\") as fh:\n",
    "        feature_dict[k] = list(csv.reader(fh, delimiter=\"\\t\"))\n",
    "\n",
    "    gene_dict_i[k] = {g[1]: i for i, g in enumerate(feature_dict[k])}\n",
    "\n",
    "for fp in data_path.glob(\"pipseq*/raw_matrix/\"):\n",
    "    k = fp.parent.name\n",
    "    print(fp)\n",
    "    with gzip.open(fp / \"barcodes.tsv.gz\", \"rt\") as fh:\n",
    "        bc_dict[k] = [line.strip() for line in fh]\n",
    "\n",
    "    with gzip.open(fp / \"features.tsv.gz\", \"rt\") as fh:\n",
    "        feature_dict[k] = list(csv.reader(fh, delimiter=\"\\t\"))\n",
    "\n",
    "    gene_dict_i[k] = {g[1]: i for i, g in enumerate(feature_dict[k])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f9e314-ce9b-47b8-8e37-8ef360d32ef2",
   "metadata": {},
   "source": [
    "### Basic stats\n",
    "\n",
    "We compute a bunch of basic stats, such as nUMIs/cell and nGenes/cell. We'll need some of these for gene selection and clustering so we'll save them for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb4d0ea-0675-45a2-ba9f-2275a48f341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the shortread files for the PBMC data\n",
    "npz_files = {k: next((data_path / k).glob(f\"**/{k}.npz\")) for k in SHORTREAD_KEYS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070aa00-7e14-4672-9823-ba0d66f744d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll cache these in a pickle \n",
    "stats_file = data_path / \"shortread_full_stats.pickle\"\n",
    "if not stats_file.exists():\n",
    "    numis = {k: sparse.load_npz(npz_files[k]).sum(1).todense() for k in SHORTREAD_KEYS}\n",
    "    ngenes = {k: np.sign(sparse.load_npz(npz_files[k])).change_compressed_axes((0,)).sum(1).todense() for k in SHORTREAD_KEYS}\n",
    "\n",
    "    # we will compute these later\n",
    "    ix_dict = dict()\n",
    "else:\n",
    "    # if we've already made the pickle file, this is a lot quicker\n",
    "    with stats_file.open(\"rb\") as fh:\n",
    "        d = pickle.load(fh)\n",
    "        numis = d[\"numis\"]\n",
    "        ngenes = d[\"ngenes\"]\n",
    "\n",
    "        # these are computed later\n",
    "        ix_dict = d[\"ix_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af15a9c-d401-4b9c-8e37-cb2f0e6f2df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total nUMIs per experiment--these were not loaded equally on the flowcell\n",
    "for k in SHORTREAD_KEYS:\n",
    "    print(f\"{k}\\tnumis: {numis[k].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de347488-ca23-4e57-b28b-3b8e7b13096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kneeplots\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "for k in SHORTREAD_KEYS:\n",
    "    ax.plot(sorted(numis[k], reverse=True), label=SHORTREAD_NAMES[k], color=SAMPLE_COLORS[SHORTREAD_NAMES[k]])\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(\"kneeplots for short-read scRNA (full data)\", fontsize=\"medium\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2166d5-4e29-4351-9ee0-a1db74046aa3",
   "metadata": {},
   "source": [
    "Above we plot kneeplots (barcodes sorted by # UMIs, in descending order) for each of the PBMC datasets. The PIPseq data has lower UMI counts but contains considerably more barcodes above 1000 UMIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5cf476-ab49-4f62-8eb2-400966463303",
   "metadata": {},
   "source": [
    "### Cell selection\n",
    "\n",
    "We're using a very simple filter here: we select all barcodes >1000 nUMIs. There is additional filtering that could be done (for instance, we are not filtering based on mitochondrial percent) but for our analysis a simple threshold was sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb421a38-2bf0-47a3-9cf0-8c48d987f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ix_dict) == 0:\n",
    "    for k in SHORTREAD_KEYS:\n",
    "        ix_dict[k] = numis[k] > 1000\n",
    "\n",
    "# total nUMIs per experiment--these were not loaded equally on the flowcell\n",
    "for k in SHORTREAD_KEYS:\n",
    "    print(k)\n",
    "    print(f\"numis: {numis[k].sum():,}\\tbarcodes: {ix_dict[k].sum():,}\\t\\tnumis in barcodes: {numis[k][ix_dict[k]].sum():,}\")\n",
    "\n",
    "if not stats_file.exists():\n",
    "    with stats_file.open(\"wb\") as out:\n",
    "        pickle.dump(\n",
    "            {\n",
    "                \"numis\": numis,\n",
    "                \"ngenes\": ngenes,\n",
    "                \"ix_dict\": ix_dict,\n",
    "            },\n",
    "            out\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1e770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31c906a3-160c-4497-8257-12630258669e",
   "metadata": {},
   "source": [
    "# Subsampling\n",
    "\n",
    "Now that we have an estimate of the number of cells in each experiment, we will subsample our BAMs to have roughly equal number of reads per cell.\n",
    "\n",
    "To skip all of this, download the `subsample_stats.pickle` file and go to **Saturation plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b065db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download the subsampling stats only\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/notebook_checkpoints/subsample_stats.pickle {data_path}\n",
    "\n",
    "# uncomment to download the BAM files. Warning: these are huge\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/pbmc_pipseq/starsolo_out.bam {data_path}/pipseq_pbmc/starsolo_out.bam\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/pbmc_10x_3p/outs/possorted_genome_bam.bam {data_path}/10x_3p_pbmc/outs/possorted_genome_bam.bam\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/pbmc_10x_3p/outs/possorted_genome_bam.bam {data_path}/10x_5p_pbmc/outs/possorted_genome_bam.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663805e3-f67e-4bce-b95f-d5e600146b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_stats = data_path / \"subsample_stats.pickle\"\n",
    "\n",
    "sample_bams = {\n",
    "    \"pipseq_pbmc\": data_path / \"pipseq_pbmc\" / \"starsolo_out.bam\",\n",
    "    \"10x_3p_pbmc\": data_path / \"10x_3p_pbmc\" / \"outs\" / \"possorted_genome_bam.bam\",\n",
    "    \"10x_5p_pbmc\": data_path / \"10x_5p_pbmc\" / \"outs\" / \"possorted_genome_bam.bam\",\n",
    "}\n",
    "\n",
    "sample_bug_npz = {\n",
    "    \"pipseq_pbmc\": data_path / \"pipseq_pbmc\" / \"pipseq_pbmc_full.bug_vec.npz\",\n",
    "    \"10x_3p_pbmc\": data_path / \"10x_3p_pbmc\" / \"10x_3p_pbmc_full.bug_vec.npz\",\n",
    "    \"10x_5p_pbmc\": data_path / \"10x_5p_pbmc\" / \"10x_5p_pbmc_full.bug_vec.npz\",\n",
    "}\n",
    "\n",
    "# first element is the tag used for gene assignment\n",
    "# second element is whether to use 10x's \"xf\" filter\n",
    "sample_args = {\n",
    "    \"pipseq_pbmc\": (\"gx\", False),\n",
    "    \"10x_3p_pbmc\": (\"GX\", True),\n",
    "    \"10x_5p_pbmc\": (\"GX\", True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0047f-f245-4bc4-90e1-a264593596f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number barcodes and number of genes for a range of UMI thresholds\n",
    "def calc_stats(m, thresholds):\n",
    "    barcodes = m.sum(1).todense()[:, None] > thresholds\n",
    "\n",
    "    n_barcodes = barcodes.sum(0)\n",
    "    n_genes = np.sign(m).sum(1).todense()\n",
    "    n_genes = [n_genes[barcodes[:,i]] for i in range(barcodes.shape[1])]\n",
    "    \n",
    "    return n_barcodes, n_genes\n",
    "\n",
    "\n",
    "# returns the nUMI distribution over a given threshold\n",
    "def numi_dist(m, threshold=1000):\n",
    "    numis = m.sum(1).todense()\n",
    "    return numis[numis > threshold]\n",
    "\n",
    "\n",
    "# called bugzapper and save the output as an npz file\n",
    "def make_bug_array(input_bam, out_path, barcodes, feature_list, gt, check_xf):\n",
    "    bug_vec = np.array(\n",
    "        bugzapper.build_bug_vec(input_bam, barcodes, feature_list, gt, check_xf)\n",
    "    )\n",
    "    np.savez(out_path, bug_vec=bug_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e51c8-e5cb-4d41-ab8b-ebc85b2d4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output from this cell can be downloaded, to avoid downloading the raw BAM files\n",
    "for key in SHORTREAD_KEYS:\n",
    "    out_path = sample_bug_npz[key]\n",
    "    print(sample_bams[key], out_path.name, sample_args[key], end=\" \")\n",
    "    feature_list = [r[0] for r in feature_dict[key]]\n",
    "    if not out_path.exists():\n",
    "        make_bug_array(\n",
    "            sample_bams[key],\n",
    "            out_path,\n",
    "            bc_dict[key],\n",
    "            feature_list,\n",
    "            *sample_args[key],\n",
    "        )\n",
    "    else:\n",
    "        print(\"... already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2d8b4-f8a2-43af-8683-2f1e8bea6697",
   "metadata": {},
   "source": [
    "### Subsampling procedure\n",
    "\n",
    "The above code takes the BAM file and creates a large but _relatively_ compact array that summarizes the read counts for each UMI. Each row in the array represents one UMI, with indexes into the barcode and feature lists, as well as a read count.\n",
    "\n",
    "To subsample the data, we can sample the read counts with a binomial distribution corresponding to the depth we want to achieve. Any UMI that has â‰¥1 read remaining will be counted in the resulting subsample. By creating the array above we can efficiently try many different subsamples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485406e-5551-4448-9947-28a16860b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subsampled bug_vec arrays at 1k, 2k ... 10k, 15k ... 100k reads per cell\n",
    "# 100k is very slightly higher than the depth of the PIPseq data so we will just use\n",
    "# the full data there\n",
    "reads_per_cell = np.hstack(\n",
    "    [np.arange(1000, 10000, 1000), np.arange(10000, 100001, 5000)]\n",
    ")\n",
    "\n",
    "# consider various nUMI thresholds\n",
    "thresholds = np.array([[100, 200, 500, 1000, 2000, 5000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2213c2e-bf86-495d-96a4-adb874339157",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in SHORTREAD_KEYS:\n",
    "    print(SHORTREAD_NAMES[key], end=\" \")\n",
    "    subsample_p = data_path / key / \"subsample\"\n",
    "    subsample_p.mkdir(exist_ok=True)\n",
    "\n",
    "    if all((subsample_p / f\"{key}_{rpc // 1000}k.npz\").exists() for rpc in reads_per_cell):\n",
    "        print(\"... all files present\")\n",
    "        continue\n",
    "\n",
    "    full_data = np.load(sample_bug_npz[key])[\"bug_vec\"]\n",
    "    n_reads = full_data[:, 2].sum()\n",
    "\n",
    "    for rpc in reads_per_cell:\n",
    "        pct = ix_dict[key].sum() * rpc / n_reads\n",
    "        print(f\"{rpc}\", end=\" \")\n",
    "        output = subsample_p / f\"{key}_{rpc // 1000}k.npz\"\n",
    "        if output.exists():\n",
    "            continue\n",
    "\n",
    "        if pct < 1.0:\n",
    "            v = (rng.binomial(full_data[:, 2], pct) > 0).astype(int)\n",
    "        else:\n",
    "            v = np.ones(full_data.shape[0], dtype=int)\n",
    "\n",
    "        m = sparse.COO(\n",
    "            full_data[:, :2].T,\n",
    "            data=v,\n",
    "            shape=(len(bc_dict[key]), len(feature_dict[key])),\n",
    "            fill_value=0,\n",
    "            prune=True\n",
    "        ).asformat(\"gcxs\", compressed_axes=(0,))\n",
    "\n",
    "        sparse.save_npz(output, m)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6ef44-1858-4ada-8b39-f0597682431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "umi_threshold = 1000\n",
    "\n",
    "if not subsample_stats.exists():\n",
    "    # rpc -> threshold -> n\n",
    "    n_barcodes = defaultdict(lambda: defaultdict(dict))\n",
    "    # rpc -> threshold -> array\n",
    "    n_genes = defaultdict(lambda: defaultdict(dict))\n",
    "    numi_percentiles = defaultdict(list)\n",
    "\n",
    "    for key in SHORTREAD_KEYS:\n",
    "        print(SHORTREAD_NAMES[key], end=\" \")\n",
    "        subsample_p = data_path / key / \"subsample\"\n",
    "        for rpc in reads_per_cell:\n",
    "            print(rpc, end=\" \")\n",
    "            m = sparse.load_npz(subsample_p / f\"{key}_{rpc // 1000}k.npz\")\n",
    "            ndist = numi_dist(m, umi_threshold)\n",
    "            if len(ndist):\n",
    "                numi_percentiles[key].append(np.percentile(ndist, (25, 50, 75)))\n",
    "            else:\n",
    "                numi_percentiles[key].append([0.0, 0.0, 0.0])\n",
    "            n_barcodes[key][rpc], n_genes[key][rpc] = calc_stats(m, thresholds)    \n",
    "    \n",
    "        print()\n",
    "\n",
    "    n_barcodes = {key: dict(d) for key, d in n_barcodes.items()}\n",
    "    n_genes = {key: dict(d) for key, d in n_genes.items()}\n",
    "    numi_percentiles = {key: np.vstack(d) for key, d in numi_percentiles.items()}\n",
    "\n",
    "    with subsample_stats.open(\"wb\") as out:\n",
    "        pickle.dump((n_barcodes, n_genes, numi_percentiles), out)\n",
    "\n",
    "else:\n",
    "    with subsample_stats.open(\"rb\") as fh:\n",
    "        n_barcodes, n_genes, numi_percentiles = pickle.load(fh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5c752",
   "metadata": {},
   "source": [
    "### Saturation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ab970-36d6-4f0c-9883-b1a71f3ac60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    1, 3, figsize=(18, 6), sharex=True, sharey=True,\n",
    "    gridspec_kw={\"wspace\": 0.1, \"hspace\": 0.1, \"bottom\": 0.15}\n",
    ")\n",
    "\n",
    "for key, ax in zip(SHORTREAD_KEYS, axs.flat):\n",
    "    ax.plot(\n",
    "        reads_per_cell, \n",
    "        np.vstack([n_barcodes[key][rpc] for rpc in reads_per_cell]),\n",
    "        label=thresholds.flatten(),\n",
    "    )\n",
    "\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"Reads per barcode\")\n",
    "    ax.set_title(SHORTREAD_NAMES[key])\n",
    "\n",
    "fig.legend(*ax.get_legend_handles_labels(), ncols=6, loc=\"lower center\")\n",
    "axs[0].set_ylabel(\"#BC above UMI threshold\")\n",
    "fig.suptitle(\"Supplemental figure: # barcodes at different subsampling rates\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd964d-93c7-4f0a-8653-addc1815f458",
   "metadata": {},
   "source": [
    "This plot above shows how the number of barcodes changes with subsampling, using a variety of thresholds. We see that all three of the experiments are quite saturated in terms of the cells--even at 10% subsampling we see almost every barcode. The low-threshold curves reflect that as sequencing continues, empty droplets accumulate more and more UMIs. PIPseq has far more empty droplets and appears to have more ambient mRNA, so these curves are noticeably higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61cba8-ddb2-4e57-8c4a-1b4fe4d2b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "for key in SHORTREAD_KEYS:\n",
    "    ax.plot(\n",
    "        reads_per_cell, \n",
    "        numi_percentiles[key][:, 1],\n",
    "        linewidth=2,\n",
    "        c=SAMPLE_COLORS[SHORTREAD_NAMES[key]],\n",
    "        label=SHORTREAD_NAMES[key],\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        reads_per_cell,\n",
    "        numi_percentiles[key][:,0],\n",
    "        numi_percentiles[key][:,2],\n",
    "        alpha=0.1,\n",
    "        color=SAMPLE_COLORS[SHORTREAD_NAMES[key]],\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"Reads per barcode\")\n",
    "ax.set_ylabel(\"#UMIS (barcode > 1000 UMIs)\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_title(\"UMI distributions for called barcodes\")\n",
    "\n",
    "plt.savefig(figure_path / \"supp_fig12.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc0aed-372c-428a-8067-d0c7922bdafd",
   "metadata": {},
   "source": [
    "This plot show the distribution of UMIs/cell as sequencing depth increases. The shaded area is the 50% region around the median. Again these experiments are fairly well saturated, although there is less of a plateau here than in the barcode plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950acfa0-337f-46bd-8031-eb5d5467bbc0",
   "metadata": {},
   "source": [
    "## Using subsampled data for metrics and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec37fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download the subsampled npz files, if desired\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/pbmc_10x_3p/subsample/10x_3p_pbmc_100k.npz {data_path}/10x_3p_pbmc/subsample/\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/pbmc_10x_5p/subsample/10x_5p_pbmc_100k.npz {data_path}/10x_5p_pbmc/subsample/\n",
    "! # gcloud storage cp gs://mdl-sc-isoform-2025-ms/pbmc_pipseq/subsample/pipseq_pbmc_100k.npz {data_path}/pipseq_pbmc/subsample/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9bed7-f07c-4f49-a6a1-85780d5c097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_npz = {\n",
    "    k: data_path / k / \"subsample\" / f\"{k}_100k.npz\" for k in SHORTREAD_KEYS\n",
    "}\n",
    "\n",
    "# we'll cache these in a pickle\n",
    "stats_file = data_path / \"shortread_stats_100k.pickle\"\n",
    "if not stats_file.exists():\n",
    "    subsampled_numis = {\n",
    "        k: sparse.load_npz(subsampled_npz[k]).sum(1).todense()\n",
    "        for k in SHORTREAD_KEYS\n",
    "    }\n",
    "    subsampled_ngenes = {\n",
    "        k: np.sign(sparse.load_npz(subsampled_npz[k])).change_compressed_axes((0,)).sum(1).todense()\n",
    "        for k in SHORTREAD_KEYS\n",
    "    }\n",
    "\n",
    "    subsampled_ix = {k: subsampled_numis[k] > 1000 for k in SHORTREAD_KEYS}\n",
    "    subsampled_g = dict()\n",
    "else:\n",
    "    # if we've already made the pickle file, this is a lot quicker\n",
    "    with stats_file.open(\"rb\") as fh:\n",
    "        d = pickle.load(fh)\n",
    "        subsampled_numis = d[\"numis\"]\n",
    "        subsampled_ngenes = d[\"ngenes\"]\n",
    "\n",
    "        # these are computed later\n",
    "        subsampled_ix = d[\"ix_dict\"]\n",
    "        subsampled_g = d[\"sel_g\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902764a-12a6-420b-97bc-ac99cc23ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsampled nUMIs per experiment\n",
    "for k in SHORTREAD_KEYS:\n",
    "    print(k)\n",
    "    print(f\"numis: {subsampled_numis[k].sum():,}\\tbarcodes: {subsampled_ix[k].sum():,}\\t\\tnumis in barcodes: {subsampled_numis[k][subsampled_ix[k]].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbaf42-96c5-4b72-b32f-69a05950fa6c",
   "metadata": {},
   "source": [
    "### Gene Selection\n",
    "\n",
    "We're using a fairly simple deviance-from-poisson test for selecting variable genes. The basic idea is to just check if a given gene appears in fewer cells than we'd expect based on its expression--this indicates that it is not homogenously expressed in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdcc507-018a-403b-9aad-ac4b3f15f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(subsampled_g) == 0:\n",
    "    for k in SHORTREAD_KEYS:\n",
    "        m = sparse.load_npz(subsampled_npz[k])[subsampled_ix[k], :]\n",
    "        exp_nz, pct, exp_p = fit_poisson(m)\n",
    "\n",
    "        subsampled_g[k] = ((exp_nz - pct) > 0.1) & (exp_p < -5)\n",
    "\n",
    "for k in SHORTREAD_KEYS:\n",
    "    print(f\"selected genes for {k}: {subsampled_g[k].sum():,d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd37e97-9c75-42fb-9936-421bccececd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the cache file if we don't have one\n",
    "if not stats_file.exists():\n",
    "    with stats_file.open(\"wb\") as out:\n",
    "        pickle.dump(\n",
    "            {\n",
    "                \"numis\": subsampled_numis, \n",
    "                \"ngenes\": subsampled_ngenes,\n",
    "                \"ix_dict\": subsampled_ix,\n",
    "                \"sel_g\": subsampled_g,\n",
    "            },\n",
    "            out\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da8687-64eb-48cb-baac-279174ab6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in SHORTREAD_KEYS:\n",
    "    print(\n",
    "        k,\n",
    "        np.median(subsampled_numis[k][subsampled_ix[k]]),\n",
    "        np.median(subsampled_ngenes[k][subsampled_ix[k]])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af21dad-c447-49f3-b29e-b48fba5be025",
   "metadata": {},
   "source": [
    "### Supplementary figure: metrics for short-read data\n",
    "\n",
    "Supplementary figure 1 consists of kneeplots for the subsampled data, along with violin plots for UMIs/cell and genes/cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59bf570-8a1c-4e58-afdc-6c5c6bff5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = [SHORTREAD_NAMES[k] for k in SHORTREAD_KEYS]\n",
    "\n",
    "# kneeplots\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "for key in SHORTREAD_KEYS:\n",
    "    name = SHORTREAD_NAMES[key]\n",
    "    ax.plot(\n",
    "        sorted(subsampled_numis[key], reverse=True), label=name, color=SAMPLE_COLORS[name]\n",
    "    )\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "ax.set_title(\"Supplementary figure 1a: kneeplots for short-read scRNA\", fontsize=\"medium\")\n",
    "\n",
    "ax.legend(\n",
    "    handles=[\n",
    "        Line2D(markerfacecolor=SAMPLE_COLORS[n], label=n, **line_kwargs)\n",
    "        for n in sample_names\n",
    "    ],\n",
    "    loc=\"lower left\"\n",
    ")\n",
    "plt.savefig(figure_path / \"supp_fig1a.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5474d5d0-38dc-4384-91bc-3f3f2cc7439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(8, 8))\n",
    "\n",
    "plot_dists(\n",
    "    ax[0],\n",
    "    [subsampled_numis[k][subsampled_ix[k]] for k in SHORTREAD_KEYS], \n",
    "    log=True,\n",
    "    colors=[SAMPLE_COLORS[n] for n in sample_names],\n",
    "    labels=sample_names,\n",
    "    title=\"# UMIs per cell\",\n",
    ")\n",
    "ax[0].set_yticks([3, 4], minor=False)\n",
    "ax[0].set_yticks(\n",
    "    np.log10([900, *np.linspace(2000, 9000, 8), *np.linspace(20000, 70000, 6)]),\n",
    "    minor=True\n",
    ")\n",
    "\n",
    "plot_dists(\n",
    "    ax[1],\n",
    "    [subsampled_ngenes[k][subsampled_ix[k]] for k in SHORTREAD_KEYS], \n",
    "    log=True,\n",
    "    colors=[SAMPLE_COLORS[n] for n in sample_names],\n",
    "    labels=sample_names,\n",
    "    title=\"# genes per cell\",\n",
    ")\n",
    "ax[1].set_yticks([2, 3, 4], minor=False)\n",
    "ax[1].set_yticks(\n",
    "    np.log10([v*10**i for i in range(1, 4) for v in range(2, 10)][3:]),\n",
    "    minor=True\n",
    ")\n",
    "\n",
    "\n",
    "fig.suptitle(\"Supplementary figure 1bc: UMI and gene distributions for short-read data\")\n",
    "plt.savefig(figure_path / \"supp_fig1bc.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f50584e-b9dc-455f-a219-34799b6e694c",
   "metadata": {},
   "source": [
    "### Graph embedding\n",
    "\n",
    "We calculate a shared-nearest neighbor graph (using code in `isoscelles`) and then use graphviz to make a graph embedding with the `sfdp` algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8cf29-ed1d-43d0-b8b9-9048e3424ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again we're going to cache these for easy re-runs\n",
    "graph_file = data_path / \"shortread_graphs_100k.pickle\"\n",
    "graph_file.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804e452-152e-4a4c-96d5-51f4324dc8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not graph_file.exists():\n",
    "    coords = dict()\n",
    "\n",
    "    for k in SHORTREAD_KEYS:\n",
    "        print(k)\n",
    "        exp = sparse.load_npz(subsampled_npz[k])[subsampled_ix[k], :][:, subsampled_g[k]]\n",
    "        graph = nbrs.calc_graph(np.sqrt(exp))\n",
    "        coords[k] = layout_graph(graph)\n",
    "\n",
    "    # the graph embedding has arbitrary orientation, we might need to flip the coordinates\n",
    "    # around to match cell types up in the different datasets\n",
    "    coords['10x_3p_pbmc'] *= np.array([[-1, 1]])  # flip 10x 3' x coordinate\n",
    "\n",
    "    with graph_file.open(\"wb\") as out:\n",
    "        pickle.dump(coords, out)\n",
    "else:\n",
    "    with graph_file.open(\"rb\") as fh:\n",
    "        coords = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50857e44-65a7-4f29-bc23-92dd40afebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 6), gridspec_kw={\"hspace\": 0.1, \"wspace\": 0.1, \"bottom\": 0.15})\n",
    "for k, ax in zip(SHORTREAD_KEYS, axs.flat):\n",
    "    m = ax.scatter(\n",
    "        coords[k][:, 0], coords[k][:, 1], s=1, c=subsampled_numis[k][subsampled_ix[k]], \n",
    "        norm=colors.LogNorm(*np.percentile(subsampled_numis[k][subsampled_ix[k]], (1, 99))),\n",
    "        rasterized=True,\n",
    "    )\n",
    "    ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "    ax.set_title(SHORTREAD_NAMES[k])\n",
    "\n",
    "    axins1 = inset_axes(\n",
    "        ax,\n",
    "        width=\"20%\",\n",
    "        height=\"5%\",\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(0.05, 0.05, 0.9, 1),\n",
    "        bbox_transform=ax.transAxes,\n",
    "    )\n",
    "    axins1.xaxis.set_ticks_position(\"bottom\")\n",
    "    fig.colorbar(m, cax=axins1, orientation=\"horizontal\", ticks=[1000, 10000, 100000])\n",
    "\n",
    "fig.suptitle(\"Embeddings of single cell data, colored by UMIs\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6d44e-f6d6-48e6-9f1b-ef3f10267213",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "The clustering code is in `mdl.isoscelles.leiden`. The basic strategy is:\n",
    "\n",
    "  1. Select genes using poisson test (as above)\n",
    "  2. Compute SNN graph\n",
    "  3. Cluster with Leiden algorithm over increasing range of resolutions until we find more than one cluster\n",
    "  4. Recursively subcluster the results until no more clusters are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d007928-668f-49ba-9c52-3391dde10a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_file = data_path / \"shortread_clustering_100k.pickle\"\n",
    "clustering_file.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d072d0-946e-4927-991d-9fe4deb47a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the cache file if we don't have one\n",
    "if not clustering_file.exists():\n",
    "    clustering = dict()\n",
    "\n",
    "    for k in SHORTREAD_KEYS:\n",
    "        print(k)\n",
    "        res_list = [float(f\"{b}e{p}\") for p in range(-7, -2) for b in range(1, 10)]\n",
    "        data = sparse.load_npz(subsampled_npz[k])[subsampled_ix[k], :]\n",
    "        clustering[k] = recursive_cluster(data, res_list, feature_cutoff_pct=0.05)\n",
    "    with clustering_file.open(\"wb\") as out:\n",
    "        pickle.dump(clustering, out)\n",
    "else:\n",
    "    with clustering_file.open(\"rb\") as fh:\n",
    "        clustering = pickle.load(fh)\n",
    "\n",
    "for k in SHORTREAD_KEYS:\n",
    "    print(f\"{k}: found {len(cluster_leaf_nodes(clustering[k][0], n=80)):2d} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60de4bb-ff30-4735-84b6-d0175e7bbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_arrays = dict()\n",
    "for key in SHORTREAD_KEYS:\n",
    "    _leaf_nodes = cluster_leaf_nodes(clustering[key][0])\n",
    "    _label_array = cluster_labels(clustering[key][0], _leaf_nodes)\n",
    "    _k2i = {k: i for i, k in enumerate(sorted(_leaf_nodes))}    \n",
    "    c_arrays[key] = np.array([_k2i.get(k, -1) for k in _label_array])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f076bfb-b91f-4c8d-a64a-50898d76fc2a",
   "metadata": {},
   "source": [
    "#### Markers\n",
    "\n",
    "Here we go through a list of markers for various cell types and plot expression on our embeddings. Note: we need the data files for this, it isn't stored in the pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ba7a7-c12c-40ff-b22a-79a49dea148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_markers(markers):\n",
    "    _, axs = plt.subplots(\n",
    "        len(markers), 3, figsize=(9, len(markers) * 3), squeeze=False, gridspec_kw={\"hspace\": 0.1, \"wspace\": 0.1}\n",
    "    )\n",
    "\n",
    "    for i,k in enumerate(SHORTREAD_KEYS):\n",
    "        d = sparse.load_npz(subsampled_npz[k])[subsampled_ix[k], :]\n",
    "        for j,g in enumerate(markers):\n",
    "            d2 = d[:, gene_dict_i[k][g]].todense()\n",
    "\n",
    "            axs[j, i].scatter(coords[k][:, 0], coords[k][:, 1], s=1, cmap=\"Blues\", c=np.log1p(d2), alpha=0.8)\n",
    "            axs[j, i].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "        axs[0, i].set_title(SHORTREAD_NAMES[k])\n",
    "\n",
    "    for j,g in enumerate(markers):\n",
    "        axs[j, 0].set_ylabel(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32b4ef-33a8-4beb-9a9c-492cbf2145fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = [\n",
    "    \"CD8A\", \"CD3D\", \"CD4\", \"CD14\", \"CCR7\", \"SELL\",\n",
    "    \"FCGR3A\", \"CLEC10A\", \"CD1C\", \"NKG7\", \"NCAM1\", \"GNLY\",\n",
    "    \"MS4A1\", \"IGKC\", \"IGLC2\", \"IRF7\", \"IGHM\", \"JCHAIN\",\n",
    "]\n",
    "\n",
    "plot_markers(markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fbf98-d987-439d-9922-7750143bf854",
   "metadata": {},
   "source": [
    "#### Clusters\n",
    "\n",
    "We annotated the clusters based on the expression of the marker genes above. Here we plot the embedding with clusters labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044373c2-f02e-4747-9dfe-cb2d1a134dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names_colors = {\n",
    "    \"pipseq_pbmc\": {\n",
    "        0: ('CD4 T cells 1', '#006db6'),\n",
    "        1: ('CD4 T cells 2', '#3d8fc6'),\n",
    "        2: ('Naive CD4', '#7bb1d6'),\n",
    "        3: ('Cytotoxic T cells', '#b8d3e5'),\n",
    "        4: ('Innate Lymphoid', '#80BC42'),\n",
    "        5: ('CD16 Monocytes', '#888b8d'),\n",
    "        6: ('CD14 Monocytes', '#4eeebb'),\n",
    "        7: ('B cells', '#f36c3e'),\n",
    "    },\n",
    "    \"10x_3p_pbmc\": {\n",
    "        0: ('CD4 T cells 1', '#006db6'),\n",
    "        1: ('CD4 T cells 2', '#3d8fc6'),\n",
    "        2: ('Naive CD4', '#7bb1d6'),\n",
    "        3: ('Cytotoxic T cells', '#b8d3e5'),\n",
    "        4: ('B cells', '#f36c3e'),\n",
    "        5: ('CD14 Monocytes', '#4eeebb'),\n",
    "        6: ('CD16 Monocytes', '#888b8d'),\n",
    "        7: ('DC', '#0a2240'),\n",
    "    },\n",
    "    \"10x_5p_pbmc\": {\n",
    "        0: ('CD4 T cells 1', '#006db6'),\n",
    "        1: ('CD4 T cells 2', '#3d8fc6'),\n",
    "        2: ('Naive CD4', '#7bb1d6'),\n",
    "        3: ('Cytotoxic T cells', '#b8d3e5'),\n",
    "        4: ('Innate Lymphoid', '#80BC42'),\n",
    "        5: ('B cells', '#f36c3e'),\n",
    "        6: ('CD14 Monocytes', '#4eeebb'),\n",
    "        7: ('CD16 Monocytes', '#888b8d'),\n",
    "    }\n",
    "}\n",
    "\n",
    "labels = [\n",
    "    (cluster_names_colors[k][i][0], SHORTREAD_NAMES[k])\n",
    "    for k in SHORTREAD_KEYS for i in sorted(cluster_names_colors[k])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f5297-b9ed-470d-a6e5-d9c63c0b780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for supplementary table 1 (when reformatted)\n",
    "for key in SHORTREAD_KEYS:\n",
    "    print(key, (c_arrays[key] > -1).sum())\n",
    "    for i,lbl in sorted(cluster_names_colors[key].items(), key=lambda i: i[1]):\n",
    "        print(i, f\"{(c_arrays[key] == i).sum():5,}\", f\"{(c_arrays[key] == i).sum() / c_arrays[key].shape[0]:6.1%}\", lbl[0], sep=\"\\t\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779411a4-01b5-4302-adce-7e11b5bb24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 6), gridspec_kw={\"hspace\": 0.1, \"wspace\": 0.1, \"bottom\": 0.15})\n",
    "for k, ax in zip(SHORTREAD_KEYS, axs.flat):\n",
    "    ix = c_arrays[k] > -1\n",
    "\n",
    "    # an array of cluster labels for all cells, including the\n",
    "    # ones that were not fully assigned\n",
    "    c = np.array([cluster_names_colors[k][i][1] for i in c_arrays[k][ix]])\n",
    "\n",
    "    ax.scatter(coords[k][ix, 0], coords[k][ix, 1], s=1, c=c, alpha=0.8, rasterized=True)\n",
    "    ax.set_title(SHORTREAD_NAMES[k])\n",
    "    ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "fig.legend(\n",
    "    handles=[\n",
    "        Line2D(markerfacecolor=c, label=lbl, **line_kwargs)\n",
    "        for lbl,c in sorted({lbl_c for key in SHORTREAD_KEYS for lbl_c in cluster_names_colors[key].values()})\n",
    "    ],\n",
    "    loc=\"lower center\", ncol=3, fontsize=\"medium\",\n",
    ")\n",
    "\n",
    "plt.savefig(figure_path / \"fig1a_clustering.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2175d-5f18-4ecc-a678-87000274a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index into our arrays for the marker genes \n",
    "marker_ix = {tuple(gene_dict_i[k][g] for g in markers) for k in SHORTREAD_KEYS}\n",
    "assert len(marker_ix) == 1\n",
    "marker_ix = marker_ix.pop()\n",
    "\n",
    "label_ix = sorted(range(len(labels)), key=lambda i: labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e68bae6-997c-447d-8652-18626f16822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % nonzero for each gene x cluster\n",
    "pseudobulk_arrays = dict()\n",
    "# mean UMIs/cell for each gene x cluster\n",
    "pseudobulk_count_arrays = dict()\n",
    "\n",
    "for k in SHORTREAD_KEYS:\n",
    "    d = sparse.load_npz(subsampled_npz[k])[subsampled_ix[k], :]\n",
    "\n",
    "    pseudobulk_arrays[k] = np.vstack(\n",
    "        [\n",
    "            np.sign(d[c_arrays[k] == i, :]).mean(0).todense()\n",
    "            for i in np.unique(c_arrays[k]) if i != -1\n",
    "        ]\n",
    "    )\n",
    "    pseudobulk_count_arrays[k] = np.vstack(\n",
    "        [\n",
    "            (d[c_arrays[k] == i, :]).mean(0).todense() \n",
    "            for i in np.unique(c_arrays[k]) if i != -1\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c966e87-852a-4a43-92ea-d1fc430e5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the arrays across samples to plot a combined dotplot\n",
    "marker_nz = np.vstack([pseudobulk_arrays[k][:, marker_ix] for k in SHORTREAD_KEYS]).T\n",
    "marker_counts = np.vstack([pseudobulk_count_arrays[k][:, marker_ix] for k in SHORTREAD_KEYS]).T\n",
    "\n",
    "plot_marker_dotplot(\n",
    "    labels,\n",
    "    markers,\n",
    "    marker_nz,\n",
    "    marker_counts,\n",
    "    label_ix,\n",
    "    figure_path / \"fig1b_dotplot.svg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104084fb-763a-4b52-874b-c6daa76bd2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdl-sc-isoform-2025-ms",
   "language": "python",
   "name": "mdl-sc-isoform-2025-ms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
